{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mistral as a Question Answering \n",
    "---\n",
    "##  Environment Variables and API Keys\n",
    "\n",
    "In this notebook, we will demonstrate how to securely handle `inDox` as system for question answering system with open source models which are available on internet like `Mistral`. so firstly you should buil environment variables and API keys in Python using the `dotenv` library. Environment variables are a crucial part of configuring your applications, especially when dealing with sensitive information like API keys.\n",
    "\n",
    "::: {.callout-note}\n",
    "Because we are using **HuggingFace** models you need to define your `HF_API_KEY` in `.env` file. This allows us to keep our API keys and other sensitive information out of our codebase, enhancing security and maintainability.\n",
    ":::\n",
    "Let's start by importing the required libraries and loading our environment variables.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1497e4a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:08.946016Z",
     "start_time": "2024-05-20T13:46:08.898710Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "HF_API_KEY = os.getenv('HF_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6ff7e",
   "metadata": {},
   "source": [
    "### Import Essential Libraries \n",
    "Then, we import essential libraries for our `Indox` question answering system:\n",
    "- `IndoxRetrievalAugmentation`: Enhances the retrieval process for better QA performance.\n",
    "- `MistralQA`: A powerful QA model from Indox, built on top of the Hugging Face model.\n",
    "- `HuggingFaceEmbedding`: Utilizes Hugging Face embeddings for improved semantic understanding.\n",
    "- `UnstructuredLoadAndSplit`: A utility for loading and splitting unstructured data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9470496cd9a78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:46.343004Z",
     "start_time": "2024-05-20T13:46:09.122327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 17:16:14,149 - INFO - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-05-20 17:16:14,149 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from Indox import IndoxRetrievalAugmentation\n",
    "from Indox.QaModels import MistralQA\n",
    "from Indox.Embeddings import HuggingFaceEmbedding\n",
    "from Indox.DataLoaderSplitter import UnstructuredLoadAndSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5abc55",
   "metadata": {},
   "source": [
    "### Building the Indox System and Initializing Models\n",
    "\n",
    "Next, we will build our `inDox` system and initialize the Mistral question answering model along with the embedding model. This setup will allow us to leverage the advanced capabilities of Indox for our question answering tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c279c0844b08ffc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:48.029295Z",
     "start_time": "2024-05-20T13:46:46.343004Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 17:16:46,468 - INFO - Load pretrained SentenceTransformer: multi-qa-mpnet-base-cos-v1\n",
      "2024-05-20 17:16:48,013 - INFO - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "indox = IndoxRetrievalAugmentation()\n",
    "mistral_qa = MistralQA(api_key=HF_API_KEY,model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "embed = HuggingFaceEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d054c3f",
   "metadata": {},
   "source": [
    "### Setting Up Reference Directory and File Path\n",
    "\n",
    "To demonstrate the capabilities of our Indox question answering system, we will use a sample directory. This directory will contain our reference data, which we will use for testing and evaluation.\n",
    "\n",
    "First, we specify the path to our sample file. In this case, we are using a file named `sample.txt` located in our working directory. This file will serve as our reference data for the subsequent steps.\n",
    "\n",
    "Let's define the file path for our reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df145b7b6f380df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:48.044923Z",
     "start_time": "2024-05-20T13:46:48.029295Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"sample.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d3250",
   "metadata": {},
   "source": [
    "### Chunking Reference Data with UnstructuredLoadAndSplit\n",
    "\n",
    "To effectively utilize our reference data, we need to process and chunk it into manageable parts. This ensures that our question answering system can efficiently handle and retrieve relevant information.\n",
    "\n",
    "We use the `UnstructuredLoadAndSplit` utility for this task. This tool allows us to load the unstructured data from our specified file and split it into smaller chunks. This process enhances the performance of our retrieval and QA models by making the data more accessible and easier to process.\n",
    "\n",
    "In this step, we define the file path for our reference data and use `UnstructuredLoadAndSplit` to chunk the data with a maximum chunk size of 400 characters.\n",
    "\n",
    "Let's proceed with chunking our reference data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb521f8180b01f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:54.028248Z",
     "start_time": "2024-05-20T13:46:48.044923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing...\n",
      "End Chunking process.\n"
     ]
    }
   ],
   "source": [
    "data = UnstructuredLoadAndSplit(file_path=file_path,max_chunk_size=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4354907",
   "metadata": {},
   "source": [
    "### Connecting Embedding Model to Indox\n",
    "\n",
    "With our reference data chunked and ready, the next step is to connect our embedding model to the Indox system. This connection enables the system to leverage the embeddings for better semantic understanding and retrieval performance.\n",
    "\n",
    "We use the `connect_to_vectorstore` method to link the `HuggingFaceEmbedding` model with our Indox system. By specifying the embeddings and a collection name, we ensure that our reference data is appropriately indexed and stored, facilitating efficient retrieval during the question-answering process.\n",
    "\n",
    "Let's connect the embedding model to Indox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30236e1432254709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:55.705117Z",
     "start_time": "2024-05-20T13:46:54.028248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 17:16:55,310 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "indox.connect_to_vectorstore(embeddings=embed,collection_name=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f09de",
   "metadata": {},
   "source": [
    "### Storing Data in the Vector Store\n",
    "\n",
    "After connecting our embedding model to the Indox system, the next step is to store our chunked reference data in the vector store. This process ensures that our data is indexed and readily available for retrieval during the question-answering process.\n",
    "\n",
    "We use the `store_in_vectorstore` method to store the processed data in the vector store. By doing this, we enhance the system's ability to quickly access and retrieve relevant information based on the embeddings generated earlier.\n",
    "\n",
    "Let's proceed with storing the data in the vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f76a288442d0957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:59.513513Z",
     "start_time": "2024-05-20T13:46:55.705117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 17:16:59,481 - INFO - Document added successfully to the vector store.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Indox.vectorstore.ChromaVectorStore at 0x19ae5c26070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indox.store_in_vectorstore(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f0662",
   "metadata": {},
   "source": [
    "## Testing the RAG System with Indox\n",
    "With our Retrieval-Augmented Generation (RAG) system built using Indox, we are now ready to test it with a sample question. This test will demonstrate how effectively our system can retrieve and generate accurate answers based on the reference data stored in the vector store.\n",
    "\n",
    "We'll use a sample query to test our system:\n",
    "- **Query**: \"How did Cinderella reach her happy ending?\"\n",
    "\n",
    "This question will be processed by our Indox system to retrieve relevant information and generate an appropriate response.\n",
    "\n",
    "Let's test our RAG system with the sample question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfe4418fe997c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:46:59.529156Z",
     "start_time": "2024-05-20T13:46:59.513513Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"How cinderella reach her happy ending?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cda2e7",
   "metadata": {},
   "source": [
    "Now that our Retrieval-Augmented Generation (RAG) system with Indox is fully set up, we can test it with a sample question. We'll use the `answer_question` submethod to get a response from the system.\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "The `answer_question` method processes the query using the connected QA model and retrieves relevant information from the vector store. It returns a list where:\n",
    "- The first index contains the answer.\n",
    "- The second index contains the contexts and their respective scores.\n",
    "\n",
    ":::\n",
    "\n",
    "We'll pass this query to the `answer_question` method and print the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca61790103f1eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:47:01.911060Z",
     "start_time": "2024-05-20T13:46:59.529156Z"
    }
   },
   "outputs": [],
   "source": [
    "response = indox.answer_question(query=query,qa_model=mistral_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bc961",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acea9ac8b16dcd11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:47:01.927081Z",
     "start_time": "2024-05-20T13:47:01.911568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cinderella reaches her happy ending by consistently asking for and receiving help from the magical bird. She expresses her wishes to the bird, and it grants them to her. However, when she goes to the festival to meet the prince, she must take off her beautiful clothes and leave them on the grave of her mother, and put on her grey gown to hide her identity. On each of the three days of the festival, she repeats this process, returning her beautiful dress to the bird and'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f585d9e",
   "metadata": {},
   "source": [
    "**Contexts and Scores:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63067c6d5ca0786a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:47:01.942721Z",
     "start_time": "2024-05-20T13:47:01.927081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['by the hearth in the cinders. And as on that account she always\\n\\nlooked dusty and dirty, they called her cinderella.\\n\\nIt happened that the father was once going to the fair, and he\\n\\nasked his two step-daughters what he should bring back for them.\\n\\nBeautiful dresses, said one, pearls and jewels, said the second.\\n\\nAnd you, cinderella, said he, what will you have. Father',\n",
       "  'cinderella expressed a wish, the bird threw down to her what she\\n\\nhad wished for.\\n\\nIt happened, however, that the king gave orders for a festival\\n\\nwhich was to last three days, and to which all the beautiful young\\n\\ngirls in the country were invited, in order that his son might choose\\n\\nhimself a bride. When the two step-sisters heard that they too were',\n",
       "  'know where she was gone. He waited until her father came, and\\n\\nsaid to him, the unknown maiden has escaped from me, and I\\n\\nbelieve she has climbed up the pear-tree. The father thought,\\n\\ncan it be cinderella. And had an axe brought and cut the\\n\\ntree down, but no one was on it. And when they got into the\\n\\nkitchen, cinderella lay there among the ashes, as usual, for she',\n",
       "  'and had run to the little hazel-tree, and there she had taken off\\n\\nher beautiful clothes and laid them on the grave, and the bird had\\n\\ntaken them away again, and then she had seated herself in the\\n\\nkitchen amongst the ashes in her grey gown.\\n\\nNext day when the festival began afresh, and her parents and\\n\\nthe step-sisters had gone once more, cinderella went to the\\n\\nhazel-tree and said -',\n",
       "  \"had jumped down on the other side of the tree, had taken the\\n\\nbeautiful dress to the bird on the little hazel-tree, and put on her\\n\\ngrey gown.\\n\\nOn the third day, when the parents and sisters had gone away,\\n\\ncinderella went once more to her mother's grave and said to the\"],\n",
       " [0.6900026202201843,\n",
       "  0.760350227355957,\n",
       "  0.8475780487060547,\n",
       "  0.8616105318069458,\n",
       "  0.873013436794281])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b14a53",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluating the performance of your question-answering system is crucial to ensure the quality and reliability of the responses. In this section, we will use the `Evaluation` module from Indox to assess our system's outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584123b814c95d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:47:07.898893Z",
     "start_time": "2024-05-20T13:47:01.942721Z"
    }
   },
   "outputs": [],
   "source": [
    "from Indox.Evaluation import Evaluation\n",
    "evaluator = Evaluation([\"BertScore\", \"Toxicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ffe30",
   "metadata": {},
   "source": [
    "### Preparing Inputs for Evaluation\n",
    "Next, we need to format the inputs according to the Indox evaluator's requirements. This involves creating a dictionary that includes the question, the generated answer, and the context from which the answer was derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942736fcd423744c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:56:01.185494Z",
     "start_time": "2024-05-20T13:56:00.384679Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"question\" : query,\n",
    "    \"answer\" : response[0],\n",
    "    \"context\" : response[1][0]\n",
    "}\n",
    "result = evaluator(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a3b62",
   "metadata": {},
   "source": [
    "### Expected Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ebedbeb57b43ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:56:01.818078Z",
     "start_time": "2024-05-20T13:56:01.786837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.578776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.582990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.575296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toxicity</th>\n",
       "      <td>0.078171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "Precision  0.578776\n",
       "Recall     0.582990\n",
       "F1-score   0.575296\n",
       "Toxicity   0.078171"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d0ba2",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "These metrics help you understand the accuracy and quality of the answers generated by your Indox RAG system.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e134a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
