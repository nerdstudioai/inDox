{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Indox Retrieval Augmentation\n",
   "id": "f454fd6293a873f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we will explore how to work with Indox Retrieval Augmentation. First, if you are using OpenAI, you should set your OpenAI key as an environment variable.",
   "id": "c67508fa389e569f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T15:22:37.787474Z",
     "start_time": "2024-06-08T15:22:37.768871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "id": "88e8c38ba3b8886d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating an instance of IndoxTetrivalAugmentation\n",
    "\n",
    "To effectively utilize the Indox Retrieval Augmentation capabilities, you must first create an instance of the IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ],
   "id": "ac995737f9b2fe6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T15:22:40.365227Z",
     "start_time": "2024-06-08T15:22:40.354141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "id": "131692307c9154db",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating response using OpenAI's language models \n",
    "OpenAIQA class is used to handle question-answering task using OpenAI's language models. This instance creates OpenAiEmbedding class to specifying embedding model. Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ],
   "id": "759db8f502cbd91f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T15:22:44.274411Z",
     "start_time": "2024-06-08T15:22:42.752443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.llms import OpenAiQA\n",
    "from indox.embeddings import OpenAiEmbedding\n",
    "openai_qa = OpenAiQA(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")\n",
    "embed_openai = OpenAiEmbedding(api_key=OPENAI_API_KEY,model=\"text-embedding-3-small\")\n",
    "\n",
    "from indox.vector_stores import ChromaVectorStore\n",
    "db = ChromaVectorStore(collection_name=\"sample\",embedding=embed_openai)\n",
    "indox.connect_to_vectorstore(vectorstore_database=db)"
   ],
   "id": "f32d98545c6d3c3c",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IndoxApiOpenAiQaAgent' from 'indox.llms.OpenAi.openai_indox_api' (C:\\Users\\ALL DIGITAL\\Development-agent-branch\\inDox\\indox\\llms\\OpenAi\\openai_indox_api.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mindox\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAiQA\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mindox\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAiEmbedding\n\u001B[0;32m      3\u001B[0m openai_qa \u001B[38;5;241m=\u001B[39m OpenAiQA(api_key\u001B[38;5;241m=\u001B[39mOPENAI_API_KEY, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo-0125\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Development-agent-branch\\inDox\\indox\\llms\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mMistral\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MistralQA\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mOpenAi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAiQA\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mDspy_Cot\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DspyCotQA\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mOpenAi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IndoxApiOpenAiQa,IndoxApiOpenAiQaAgent\n",
      "File \u001B[1;32m~\\Development-agent-branch\\inDox\\indox\\llms\\OpenAi\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mopenai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAiQA\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mopenai_indox_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IndoxApiOpenAiQa,IndoxApiOpenAiQaAgent\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'IndoxApiOpenAiQaAgent' from 'indox.llms.OpenAi.openai_indox_api' (C:\\Users\\ALL DIGITAL\\Development-agent-branch\\inDox\\indox\\llms\\OpenAi\\openai_indox_api.py)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### load and preprocess data\n",
    "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
   ],
   "id": "1e3408e8f8a8ad17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "file_path = \"sample.txt\"",
   "id": "1d8e56a9f88e03cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from indox.data_loader_splitter import UnstructuredLoadAndSplit\n",
    "loader_splitter = UnstructuredLoadAndSplit(file_path=file_path,max_chunk_size=400)\n",
    "docs = loader_splitter.load_and_chunk()"
   ],
   "id": "827c44ce67f972c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "docs",
   "id": "82af3fb1c9f5643a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "indox.store_in_vectorstore(docs=docs)",
   "id": "4557891dec337e31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retrieve relevant information and generate an answer\n",
    "The main purpose of these lines is to perform a query on the vector store to retrieve the most relevant information (top_k=5) and generate an answer using the language model."
   ],
   "id": "cd6bd4924ad116fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"How Cinderella reach her happy ending?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db, llm=openai_qa, top_k=5)"
   ],
   "id": "593ec3a85c796115"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "invoke(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
    "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
   ],
   "id": "9e778403c8d864c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "retriever.invoke(query)\n",
    "retriever.context"
   ],
   "id": "58d79450c0807286"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### With AgenticRag\n",
    "\n",
    "AgenticRag stands for Agentic Retrieval-Augmented Generation. This concept combines retrieval-based methods and generation-based methods in natural language processing (NLP). The key idea is to enhance the generative capabilities of a language model by incorporating relevant information retrieved from a database or a vector store. \n",
    " AgenticRag is designed to provide more contextually rich and accurate responses by utilizing external knowledge sources. It retrieves relevant pieces of information (chunks) from a vector store based on a query and then uses a language model to generate a comprehensive response that incorporates this retrieved information."
   ],
   "id": "486878b3d49c9871"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "agent = indox.AgenticRag(llm=openai_qa,vector_database=db,top_k=5)\n",
    "agent.run(query)"
   ],
   "id": "394533a0e6ab8228"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
