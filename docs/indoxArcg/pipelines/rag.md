# Retrieval-Augmented Generation (RAG) Pipeline Documentation

## Overview

The **Retrieval-Augmented Generation (RAG) Pipeline** is designed to enhance the quality of responses generated by a Large Language Model (LLM) by retrieving relevant context from a vector store and optionally using advanced retrieval strategies like multi-query retrieval and smart retrieval with validation.

The pipeline supports:

- **Standard retrieval**: Retrieves context using vector similarity search.
- **Multi-query retrieval**: Expands a single query into multiple related queries for better context retrieval.
- **Smart retrieval**: Validates retrieved context for relevance and hallucination, with web search fallback.
- **Context clustering**: Optionally clusters retrieved context for better organization.

---

## Components

### 1. **RetrievalResult**

Represents a single retrieval result.

#### Attributes:

- `content`: The text content of the retrieved document.
- `score`: The similarity score of the document.

---

### 2. **QueryResult**

Represents the result of a query.

#### Attributes:

- `question`: The user's query.
- `answer`: The generated answer.
- `context`: The context used to generate the answer.

---

### 3. **BaseRetriever**

Base class for retrieval strategies.

#### Methods:

- `retrieve(query: str) -> List[RetrievalResult]`: Retrieves relevant documents for the query (must be implemented by subclasses).

---

### 4. **StandardRetriever**

Standard vector store retrieval.

#### Methods:

- `retrieve(query: str) -> List[RetrievalResult]`: Retrieves documents using vector similarity search.

---

### 5. **MultiQueryRetriever**

Multi-query retrieval strategy.

#### Methods:

- `retrieve(query: str) -> List[RetrievalResult]`: Expands the query into multiple queries and retrieves context.

---

### 6. **AnswerValidator**

Validates generated answers for quality and hallucination.

#### Methods:

- `check_hallucination(answer: str, context: List[str]) -> bool`: Checks if the answer is hallucinated based on the provided context.
- `grade_relevance(context: List[str], query: str) -> List[str]`: Grades the relevance of documents to the query.

---

### 7. **WebSearchFallback**

Handles web search when local context is insufficient.

#### Methods:

- `search(query: str) -> List[str]`: Performs a web search using DuckDuckGo and returns relevant results.

---

### 8. **RAG**

Main RAG pipeline orchestrator.

#### Initialization:

```python
def __init__(self, llm, vector_store):
```

- **llm**: The LLM instance.
- **vector_store**: The vector store instance.

# Key Methods

- **infer(question: str, top_k: int = 5, use_clustering: bool = False, use_multi_query: bool = False, smart_retrieval: bool = False) -> str**: Main query method with configurable retrieval strategy.
- **\_get_retriever(use_multi_query: bool, top_k: int) -> BaseRetriever**: Returns the appropriate retriever based on configuration.
- **\_process_context(context: List[str], query: str, use_clustering: bool) -> List[str]**: Processes and optionally clusters retrieved context.
- **\_generate_answer(context: List[str], query: str) -> str**: Generates an answer from the context.
- **\_smart_retrieve(question: str, top_k: int) -> List[str]**: Performs smart retrieval with validation and web fallback.
- **\_handle_web_fallback(question: str, top_k: int) -> List[str]**: Handles web search fallback when vector store retrieval is insufficient.

# Usage

1. **Initialization**

```python
from your_module import RAG, YourLLM, YourVectorStore

# Initialize LLM and vector store
llm = YourLLM()
vector_store = YourVectorStore()

# Initialize RAG pipeline
rag = RAG(llm, vector_store)
```

2. **Inference**

```python
question = "What is the capital of France?"
response = rag.infer(
    question=question,
    top_k=5,
    use_clustering=True,
    use_multi_query=False,
    smart_retrieval=True,
)
print(response)
```

# Retrieval Strategies

1. **Standard Retrieval**

   - Retrieves documents using vector similarity search.
   - Suitable for general-purpose retrieval.

2. **Multi-Query Retrieval**

   - Expands the query into multiple related queries.
   - Improves retrieval by capturing diverse aspects of the query.

3. **Smart Retrieval**
   - Validates retrieved context for relevance and hallucination.
   - Falls back to web search if local context is insufficient.

# Error Handling

The pipeline includes robust error handling for:

- **Context retrieval failures**: Logs an error if no relevant context is found.
- **Web search failures**: Logs a warning if web search fallback fails.
- **Hallucination detection**: Regenerates answers if hallucination is detected.

# Logging

The pipeline uses `loguru` for logging. Logs are formatted as follows:

- **INFO**: General operational messages.
- **ERROR**: Critical errors during execution.
- **WARNING**: Non-critical issues (e.g., no relevant context found).

# Example Workflow

1. Initialize the RAG pipeline with an LLM and vector store.
2. Perform inference with a user query.
3. Retrieve context using the selected retrieval strategy.
4. Process context (e.g., clustering if enabled).
5. Generate an answer using the LLM.
6. Validate the answer for relevance and hallucination.
7. Fallback to web search if local context is insufficient.

# Notes

- Ensure the `vector_store` is compatible with the `_similarity_search_with_score` method.
- The `MultiQueryRetrieval` tool should be implemented for multi-query expansion.
- The `AnswerValidator` requires the LLM to implement `check_hallucination` and `grade_docs` methods.
