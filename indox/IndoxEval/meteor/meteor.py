import re
from collections import Counter
from typing import List, Union, Tuple
from indox.IndoxEval.utils import TextPreprocessor


class METEOR:
    def __init__(self, llm_response: str, retrieval_context: Union[str, List[str]]):
        """
        Initialize the METEOR evaluator.

        Parameters:
        llm_response (str): The response generated by the LLM.
        retrieval_context (Union[str, List[str]]): The reference context(s).
        """
        self.llm_response = llm_response
        self.retrieval_context = retrieval_context

    def measure(self) -> float:
        self.score = self._calculate_score(
            llm_answer=self.llm_response, context=self.retrieval_context
        )
        return self.score

    def preprocess_text(self, text: str) -> str:
        preprocessor = TextPreprocessor()
        preprocessing_methods = [
            preprocessor.to_lower,
            preprocessor.keep_alpha_numeric,
            preprocessor.remove_number,
            preprocessor.remove_stopword,
            preprocessor.lemmatize_word,
        ]
        preprocessed_text = preprocessor.preprocess_text(text, preprocessing_methods)
        return preprocessed_text

    def tokenize(self, text: str) -> List[str]:
        return text.split()

    def precision_recall(self, candidate: str, reference: str) -> Tuple[float, float]:
        candidate_tokens = self.tokenize(self.preprocess_text(candidate))
        reference_tokens = self.tokenize(self.preprocess_text(reference))

        candidate_counts = Counter(candidate_tokens)
        reference_counts = Counter(reference_tokens)

        matches = sum((candidate_counts & reference_counts).values())
        precision = matches / len(candidate_tokens) if candidate_tokens else 0
        recall = matches / len(reference_tokens) if reference_tokens else 0

        return precision, recall

    def fragmentation_penalty(self, candidate: str, reference: str) -> float:
        candidate_tokens = self.tokenize(self.preprocess_text(candidate))
        reference_tokens = self.tokenize(self.preprocess_text(reference))

        if not candidate_tokens or not reference_tokens:
            return 0

        matches = [1 if token in reference_tokens else 0 for token in candidate_tokens]

        chunks = 1
        for i in range(1, len(matches)):
            if matches[i] == 1 and matches[i - 1] == 0:
                chunks += 1

        if matches[0] == 0:
            chunks -= 1

        return 0.5 * (chunks / sum(matches)) if sum(matches) else 0

    def meteor_score(self, candidate: str, reference: str) -> float:
        precision, recall = self.precision_recall(candidate, reference)

        if precision + recall == 0:
            f_mean = 0
        else:
            f_mean = (10 * precision) / (recall + (9 * precision))

        penalty = self.fragmentation_penalty(candidate, reference)
        score = (1 - penalty) * f_mean
        return score

    def _calculate_score(
        self, context: Union[str, List[str]], llm_answer: str
    ) -> float:
        if isinstance(context, str):
            context = [context]

        if isinstance(llm_answer, list):
            llm_answer = " ".join(llm_answer)

        scores = []
        for ctx in context:
            scores.append(self.meteor_score(llm_answer, ctx))
        average_score = sum(scores) / len(scores) if scores else 0
        return average_score
