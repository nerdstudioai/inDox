{
 "cells": [
  {
   "cell_type": "raw",
   "id": "48590ee7a230c86c",
   "metadata": {
    "id": "48590ee7a230c86c"
   },
   "source": [
    "---\n",
    "title: Load And Split With Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3d32826ee3a471",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/cookbook/indoxArcg/openai_clusterSplit.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lj_IWpNvkRbD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lj_IWpNvkRbD",
    "outputId": "01134cda-fefa-4c13-847c-d3592dd2547d",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install indoxArcg\n",
    "!pip install openai\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad3d5132199118",
   "metadata": {},
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxArcg`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indoxArcg\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indoxArcg\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indoxArcg\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indoxArcg/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec52f0c0a7c8f592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:27:55.709330Z",
     "start_time": "2024-07-24T05:27:55.696233Z"
    },
    "id": "ec52f0c0a7c8f592",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c391",
   "metadata": {
    "id": "7f71c391"
   },
   "source": [
    "## Initial Setup\n",
    "\n",
    "The following imports are essential for setting up the Indox application. These imports include the main Indox retrieval augmentation module, question-answering models, embeddings, and data loader splitter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506326bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:28:09.946126Z",
     "start_time": "2024-07-24T05:27:56.552179Z"
    },
    "id": "506326bc",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg import IndoxRetrievalAugmentation\n",
    "from indoxArcg.llms import OpenAi\n",
    "from indoxArcg.embeddings import OpenAiEmbedding\n",
    "from indoxArcg.data_loader_splitter import ClusteredSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c124de",
   "metadata": {
    "id": "d8c124de"
   },
   "source": [
    "In this step, we initialize the Indox Retrieval Augmentation, the QA model, and the embedding model. Note that the models used for QA and embedding can vary depending on the specific requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da2931c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:28:10.452446Z",
     "start_time": "2024-07-24T05:28:09.948136Z"
    },
    "id": "8da2931c",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mIndoxRetrievalAugmentation initialized\u001b[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitializing OpenAi with model: gpt-3.5-turbo-0125\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mOpenAi initialized successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized OpenAiEmbedding with model: text-embedding-3-small\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "qa_model = OpenAi(api_key=OPENAI_API_KEY,model=\"gpt-3.5-turbo-0125\")\n",
    "embed = OpenAiEmbedding(api_key=OPENAI_API_KEY,model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc88c0",
   "metadata": {
    "id": "7ddc88c0"
   },
   "source": [
    "## Data Loader Setup\n",
    "\n",
    "We set up the data loader using the `ClusteredSplit` class. This step involves loading documents, configuring embeddings, and setting options for processing the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0280aa44ef805b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5de9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:28:11.133482Z",
     "start_time": "2024-07-24T05:28:11.128235Z"
    },
    "id": "8c5de9dc",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mClusteredSplit initialized successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loader_splitter = ClusteredSplit(file_path=\"sample.txt\",embeddings=embed,remove_sword=False,re_chunk=False,chunk_size=300,summary_model=qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95f29ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:28:23.570865Z",
     "start_time": "2024-07-24T05:28:12.015562Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f95f29ed",
    "outputId": "60771a97-425e-47bb-af05-f78f49ede7c3",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting processing for documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1m--Generated 1 clusters--\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating summary for documentation\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating response\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mResponse generated successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mCompleted chunking & clustering process\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mSuccessfully obtained all documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "docs = loader_splitter.load_and_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8963612",
   "metadata": {
    "id": "b8963612"
   },
   "source": [
    "## Vector Store Connection and Document Storage\n",
    "\n",
    "In this step, we connect the Indox application to the vector store and store the processed documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28db7399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:29:06.044138Z",
     "start_time": "2024-07-24T05:29:05.775221Z"
    },
    "id": "28db7399",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg.vector_stores import Chroma\n",
    "db = Chroma(collection_name=\"sample\",embedding_function=embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0554a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:29:16.494336Z",
     "start_time": "2024-07-24T05:29:08.935889Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0554a96",
    "outputId": "dbdcd424-b293-488d-b049-52ba525b75fa",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mStoring documents in the vector store\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mDocument added successfully to the vector store.\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mDocuments stored successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.chroma.Chroma at 0x213e3f459a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add(docs=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dceb32",
   "metadata": {
    "id": "84dceb32"
   },
   "source": [
    "## Querying and Interpreting the Response\n",
    "\n",
    "In this step, we query the Indox application with a specific question and use the QA model to get the response. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e2a586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:29:17.349044Z",
     "start_time": "2024-07-24T05:29:17.346002Z"
    },
    "id": "e9e2a586",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg.pipelines.rag import RAG\n",
    "retriever = RAG(llm=qa_model,vector_store=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89e2597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:29:21.837374Z",
     "start_time": "2024-07-24T05:29:18.088690Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "c89e2597",
    "outputId": "66e536cc-ebc9-4cbc-860c-161232c9c3ec",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving context and scores from the vector database\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating answer without document relevancy filter\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mAnswering question\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating response\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mResponse generated successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mQuery answered successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Cinderella reached her happy ending by attending the royal festival with the help of a magical hazel tree and a little white bird. Despite her stepmother and stepsisters' attempts to keep her from going, Cinderella was able to attend the festival in a splendid dress and golden slippers provided by the bird. At the festival, the prince danced only with Cinderella and was captivated by her beauty. When Cinderella tried to leave, the prince tried to follow her, but she escaped. However, the prince found her golden slipper that she left behind on the staircase. The prince then searched for the owner of the slipper and eventually found Cinderella, fitting the slipper perfectly. This led to Cinderella marrying the prince and living happily ever after.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.infer(query=\"How cinderella reach happy ending?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4a7e68a73cf62",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
