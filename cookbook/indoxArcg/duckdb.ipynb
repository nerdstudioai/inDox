{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deafd62eace5fad4",
   "metadata": {},
   "source": [
    "# DuckDB \n",
    "In this notebook, we will demonstrate how to use DuckDB, for accessing and querying data efficiently. DuckDB is designed to work seamlessly with modern analytical workloads, making it a powerful tool for data analysis, research, and question-answering systems.\n",
    "\n",
    "To begin, ensure you have DuckDB installed in your Python environment. You can easily install it using `pip install duckdb`. DuckDB does not require a server, so you can start querying data directly in your local environment without any additional setup.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/cookbook/indoxArcg/duckdb.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354cdb0ba4254b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb semantic_text_splitter sentence-transformers indoxArcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43747bd79eb98e9a",
   "metadata": {},
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxArcg`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indoxArcg\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indoxArcg\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indoxArcg\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indoxArcg/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca675f19f961a233",
   "metadata": {},
   "source": [
    "### Load Hugging face API key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a24e485afc020d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:45:08.425935Z",
     "start_time": "2024-09-02T15:45:08.404678Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76889f4768e83877",
   "metadata": {},
   "source": [
    "Initialize a language model and an embedding model using the indox library with Hugging Face and Azure services. The HuggingFaceAPIModel class is used to create an instance of the Mistral-7B-Instruct model for tasks like question answering, while the AzureEmbedding would handle embedding tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104548072f255cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:45:12.311280Z",
     "start_time": "2024-09-02T15:45:11.566230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitializing HuggingFaceAPIModel with model: mistralai/Mistral-7B-Instruct-v0.2\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mHuggingFaceAPIModel initialized successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized OpenAiEmbedding with model: text-embedding-3-small\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.llms import HuggingFaceAPIModel\n",
    "from indoxArcg.embeddings import AzureOpenAIEmbeddings\n",
    "mistral_qa = HuggingFaceAPIModel(api_key=HUGGINGFACE_API_KEY,model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "azure_embed = AzureOpenAIEmbeddings(api_key=OPENAI_API_KEY,model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931615abf33be582",
   "metadata": {},
   "source": [
    "### Load Sample text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c1e58e04e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af177c8fb50f6859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:45:31.163463Z",
     "start_time": "2024-09-02T15:45:31.152713Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"sample.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ee6b3a502fe7",
   "metadata": {},
   "source": [
    "use the `RecursiveCharacterTextSplitter` class from the indox library to divide a large text into smaller, manageable chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e969fe0ee474430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:45:33.670617Z",
     "start_time": "2024-09-02T15:45:33.486877Z"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg.splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(400,20)\n",
    "content_chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba3c5890bcca9e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:45:40.214216Z",
     "start_time": "2024-09-02T15:45:40.199612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The wife of a rich man fell sick, and as she felt that her end\\n\\nwas drawing near, she called her only daughter to her bedside and\\n\\nsaid, dear child, be good and pious, and then the\\n\\ngood God will always protect you, and I will look down on you\\n\\nfrom heaven and be near you.  Thereupon she closed her eyes and\\n\\ndeparted.  Every day the maiden went out to her mother's grave,\",\n",
       " 'and wept, and she remained pious and good.  When winter came\\n\\nthe snow spread a white sheet over the grave, and by the time the\\n\\nspring sun had drawn it off again, the man had taken another wife.\\n\\nThe woman had brought with her into the house two daughters,\\n\\nwho were beautiful and fair of face, but vile and black of heart.\\n\\nNow began a bad time for the poor step-child.  Is the stupid goose',\n",
       " 'to sit in the parlor with us, they said.  He who wants to eat bread\\n\\nmust earn it.  Out with the kitchen-wench.  They took her pretty\\n\\nclothes away from her, put an old grey bedgown on her, and gave\\n\\nher wooden shoes.  Just look at the proud princess, how decked\\n\\nout she is, they cried, and laughed, and led her into the kitchen.\\n\\nThere she had to do hard work from morning till night, get up']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_chunks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15bab1d6f0612e",
   "metadata": {},
   "source": [
    "### Set up vector store\n",
    "Set up a vector store using the `DuckDB` class from the indox library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec9b87ac6b212d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:46:35.501798Z",
     "start_time": "2024-09-02T15:46:35.341780Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:03:31,777 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.vector_stores import DuckDB\n",
    "vector_store = DuckDB(\n",
    "    embedding_function=azure_embed,\n",
    "    vector_key=\"embedding\",   \n",
    "    id_key=\"id\",              \n",
    "    text_key=\"text\",          \n",
    "    table_name=\"embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730369204b63e1d4",
   "metadata": {},
   "source": [
    "### Storing Data in the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ceeda7b6051d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using engine: text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:03:34,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:35,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:36,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:37,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:37,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:38,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:39,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:39,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:40,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:40,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:41,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:41,583 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:41,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:42,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:42,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:43,499 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:44,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:44,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:45,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:45,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:46,077 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:46,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:46,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:47,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:48,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:48,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:48,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:49,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:49,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:50,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:50,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:51,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:52,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:52,854 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:53,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:53,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:54,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 17:03:54,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9bdf5adf-c389-4702-a12a-b81c92463f5c',\n",
       " 'a3bac611-fc45-4b5e-ac30-8976eb69f971',\n",
       " '3f9bb310-2933-45e1-82d7-fb68fa0b6e67',\n",
       " 'ac0a5b85-f013-4348-a844-fef414fa24b3',\n",
       " '4058a03a-2a12-44f6-a4e1-a7fa2846243b',\n",
       " '1902e169-9113-4e2b-bb0d-987073931315',\n",
       " '173de74f-9268-4c65-8023-73d1e4a94723',\n",
       " '744d3820-fcd0-4e2a-b386-15fe4e0cd309',\n",
       " '5040d7ee-63f9-4edf-ac52-46f09c90f2ba',\n",
       " '666e6dfb-1c95-432a-b28e-aaa83e16e96a',\n",
       " '15da04a3-fa30-4d15-b564-0620d0519405',\n",
       " '0e2a2afc-435d-4600-add5-b3337f9fd779',\n",
       " '943bac28-5cd9-4df4-b637-a785ec6161e0',\n",
       " '5bcebbc8-b437-4cd8-8f85-f93535edb0e5',\n",
       " '9a47b82a-569c-4972-bdca-86425a4e2ee3',\n",
       " '7257d6ed-e325-4404-9e92-f756a306d935',\n",
       " 'd4bca687-ffc8-4d65-b0a4-234e4e8fd893',\n",
       " '5464cca8-cd5b-4609-ba2b-96cd0b783a0d',\n",
       " '1aa002e0-b3ff-4ebe-9022-79c88f8a3879',\n",
       " 'af27cf5a-b575-4fb4-acb7-79386dda7065',\n",
       " '2229c46c-145a-483e-98dc-e48dfecd6088',\n",
       " 'b5095a93-501f-4d89-ac46-740a07159bb8',\n",
       " 'ebb3ecad-7619-42c5-a2a3-3f4b983035a3',\n",
       " '2cf222bb-a3ed-45c1-a321-fbe74a9be719',\n",
       " 'f9267c35-02d8-4149-aee5-4c22253f5923',\n",
       " '3bd09bbf-934d-4efb-95f4-95d475c0579a',\n",
       " 'b6adf29e-d63e-4c69-9076-70c7113b216d',\n",
       " '48ceb16f-5d98-489e-8e3c-6857c782b1fb',\n",
       " '62cda361-941c-4393-b123-3d727cabd623',\n",
       " '27e47f14-ef7b-44e7-96d1-c5b27d98518a',\n",
       " '988425c2-d705-460b-8d70-98d0a87607cc',\n",
       " '7006c6e4-0351-4f2f-84ba-8976cd040351',\n",
       " '16716549-2a68-44f0-83db-0512f421f979',\n",
       " 'ae89961c-ad61-4621-a485-7417eb246e3f',\n",
       " '2bbba8e3-a34b-4004-ae47-d50b5b771987',\n",
       " '67be2929-6f10-44d3-8cc3-3d53bf5b0282',\n",
       " 'f27f8eed-983a-4eca-9220-39640e513ae2',\n",
       " '51103b30-84fc-46cc-a366-47562a3ffba7']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(texts=content_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3701596d112cd595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:48:07.869793Z",
     "start_time": "2024-09-02T15:48:07.863428Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"How cinderella reach her happy ending?\"\n",
    "from indoxArcg.pipelines.rag import RAG\n",
    "retriever = RAG(llm=mistral_qa,vector_store=vector_store,enable_web_fallback=False,top_k= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf21be5bc8d4c2c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:48:23.386326Z",
     "start_time": "2024-09-02T15:48:20.937121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving context and scores from the vector database\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using engine: text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:03:55,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating answer without document relevancy filter\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mAnswering question\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mSending request to Hugging Face API\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mReceived successful response from Hugging Face API\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mQuery answered successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = retriever.infer(query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28b584d4be0c1800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T15:48:25.582874Z",
     "start_time": "2024-09-02T15:48:25.578673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cinderella reaches her happy ending when she attends the king's palace for the wedding wearing a golden dress and glass slippers that were magically given to her by her fairy godmother. Her step-sisters and mother do not recognize her, and she dances with the prince, who falls in love with her and identifies her as the mysterious maiden he had previously met at the ball. As they ride away together, two white doves from the hazel tree\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
