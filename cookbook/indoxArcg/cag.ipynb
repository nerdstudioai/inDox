{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('E:/Codes/inDox/libs/indoxArcg')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indoxArcg.llms import OpenAi\n",
    "from indoxArcg.embeddings import OpenAiEmbedding\n",
    "from indoxArcg.data_loaders import Txt\n",
    "from indoxArcg.splitter import RecursiveCharacterTextSplitter\n",
    "from indoxArcg.pipelines.cag import CAG, KVCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitializing OpenAi with model: gpt-4o-mini\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mOpenAi initialized successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized OpenAiEmbedding with model: text-embedding-3-small\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAi(model=\"gpt-4o-mini\",api_key=OPENAI_API_KEY)\n",
    "embed_model = OpenAiEmbedding(api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n",
    "txt_loader = Txt(txt_path=\"sample.txt\")\n",
    "splitter = RecursiveCharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "The wife of a rich man fell sick, and as she felt that her end\n",
      "\n",
      "was drawing near, she called her only daughter to her bedside and\n",
      "\n",
      "said, dear child, be good and pious, and then the\n",
      "\n",
      "good God will always protect you, and I will look down on you\n",
      "\n",
      "from heaven and be near you.  Thereupon she closed her eyes and\n",
      "\n",
      "departed.  Every day the maiden went out to her mother's grave,\n"
     ]
    }
   ],
   "source": [
    "docs = txt_loader.load()\n",
    "split_docs = splitter.split_text(text=docs)\n",
    "print(len(split_docs))\n",
    "print(split_docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mPrecomputing KV cache for 38 document chunks...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 09:30:30,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:32,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:33,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:34,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:35,015 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:36,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:38,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:39,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:40,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:41,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:42,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:43,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:44,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:45,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:46,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:47,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:48,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:48,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:49,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:50,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:51,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:52,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:53,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:54,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:55,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:56,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:56,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:57,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:58,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:30:59,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:00,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:00,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:01,387 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:02,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:02,951 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:03,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:04,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 09:31:05,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mKV cache saved: kv_cache\\embed_cache.pkl\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mPreloaded 38 document chunks into KV cache\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mPrecomputing KV cache for 38 document chunks...\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mKV cache saved: kv_cache\\no_embed_cache.pkl\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mPreloaded 38 document chunks into KV cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cag_with_embedding = CAG(\n",
    "    llm=llm,\n",
    "    \n",
    "    embedding_model=embed_model,\n",
    "    cache=KVCache(),\n",
    ")\n",
    "cache_embed_key = \"embed_cache\"\n",
    "cag_with_embedding.preload_documents(split_docs,cache_embed_key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cache_no_embed_key = \"no_embed_cache\"\n",
    "cag_without_embedding = CAG(llm=llm, cache=KVCache())\n",
    "cag_without_embedding.preload_documents(split_docs, cache_no_embed_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How Cinderella reach her happy ending?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving relevant context...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 09:31:45,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mSelected 5 relevant chunks from cache\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mPerforming inference with filtered context...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 09:31:49,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cinderella reached her happy ending through a series of magical events and '\n",
      " 'her unwavering kindness. After being mistreated by her stepmother and '\n",
      " 'stepsisters, she received help from a magical bird that granted her a '\n",
      " 'beautiful dress and slippers, allowing her to attend the royal wedding. At '\n",
      " 'the event, the prince recognized her as the beautiful maiden he had danced '\n",
      " \"with before. Despite her stepfamily's attempts to conceal her identity, the \"\n",
      " 'prince took Cinderella away on his horse, leading to their eventual '\n",
      " 'happiness together. The support of the magical tree and the bird, along with '\n",
      " 'her resilience and goodness, ultimately led to her transformation from a '\n",
      " 'mistreated girl to a beloved princess.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(cag_with_embedding.infer(query,cache_key=cache_embed_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mLoading KV cache for key: no_embed_cache\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mKV cache loaded: kv_cache\\no_embed_cache.pkl\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving relevant context...\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mSelected 0 relevant chunks from cache\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mPerforming inference with filtered context...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 09:32:16,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cinderella reaches her happy ending through a series of fortunate events '\n",
      " 'that begin with her kindness and resilience despite her difficult '\n",
      " 'circumstances. After being mistreated by her stepmother and stepsisters, she '\n",
      " 'receives help from her Fairy Godmother, who magically transforms her '\n",
      " 'appearance and provides her with a beautiful gown and glass slippers to '\n",
      " 'attend the royal ball. At the ball, she captures the heart of the prince, '\n",
      " 'but she must leave before midnight, when the magic wears off. In her haste, '\n",
      " 'she leaves behind one of her glass slippers. The prince searches the kingdom '\n",
      " 'for the owner of the slipper, and when he finds Cinderella, he realizes she '\n",
      " \"is the one he loves. They are reunited, and Cinderella's kindness and true \"\n",
      " 'identity are recognized, leading to her marriage with the prince and a life '\n",
      " 'filled with happiness.')\n"
     ]
    }
   ],
   "source": [
    "pprint(cag_without_embedding.infer(query,cache_key=cache_no_embed_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
