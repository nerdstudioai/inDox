{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b4b137e4479438",
   "metadata": {
    "id": "a0b4b137e4479438"
   },
   "source": [
    "## Indox Retrieval Augmentation\n",
    "Here, we will explore how to work with Indox Retrieval Augmentation. We are using OpenAI from Indox Api, we should set our INDOX_OPENAI_API_KEY as an environment variable.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/cookbook/indoxArcg/indox_api_openai.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fxYANSd_d72e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxYANSd_d72e",
    "outputId": "000fba73-6465-4760-cb04-658971cd555d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement indoxRag (from versions: none)\n",
      "ERROR: No matching distribution found for indoxRag\n"
     ]
    }
   ],
   "source": [
    "!pip install indoxArcg chromadb duckduckgo_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105c4c9997b2e2d",
   "metadata": {},
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxArcg`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "  python -m venv indoxArcg\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "  indoxArcg\\Scripts\\activate\n",
    "```\n",
    "\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indoxArcg\n",
    "   \n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "  source indoxArcg/bin/activate\n",
    "```\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "  pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62861510e8ede2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "--2024-12-08 18:46:41--  https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt\n",
      "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
      "OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol\n",
      "Unable to establish SSL connection.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:30:56.863773Z",
     "start_time": "2024-07-24T05:30:56.851364Z"
    },
    "collapsed": true,
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "NERD_TOKEN_API= os.getenv(\"NERD_TOKEN_API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dbe21e3fa2f2e",
   "metadata": {
    "id": "fc1dbe21e3fa2f2e"
   },
   "source": [
    "### Creating an instance of IndoxTetrivalAugmentation\n",
    "\n",
    "To effectively utilize the Indox Retrieval Augmentation capabilities, you must first create an instance of the IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d82fa001f121",
   "metadata": {
    "id": "8c7d82fa001f121"
   },
   "source": [
    "### Generating response using Indox\n",
    "IndoxApi class is used to handle question-answering task using Indox model. This instance creates IndoxOpenAIEmbedding class to specifying embedding model.By using ClusteredSplit function we can import pdf and text file and split them into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5840d601bf111608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:33:00.058510Z",
     "start_time": "2024-07-24T05:31:06.876402Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5840d601bf111608",
    "outputId": "34a39efd-1e37-478a-83c7-a7c1b255805b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized IndoxOpenAIEmbedding with model: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mClusteredSplit initialized successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting processing for documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1m--Generated 7 clusters--\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1m--Generated 1 clusters--\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mCompleted chunking & clustering process\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mSuccessfully obtained all documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary classes from Indox library\n",
    "from indoxArcg.llms import NerdToken\n",
    "from indoxArcg.embeddings import NerdTokenEmbedding\n",
    "from indoxArcg.data_loader_splitter import ClusteredSplit\n",
    "\n",
    "# Create instances for API access and text embedding\n",
    "openai_qa_indox = NerdToken(api_key=NERD_TOKEN_API)\n",
    "embed_openai_indox = NerdTokenEmbedding(api_key=NERD_TOKEN_API, model=\"text-embedding-3-small\")\n",
    "\n",
    "# Specify the path to your text file\n",
    "file_path = \"sample.txt\"\n",
    "\n",
    "# Create a ClusteredSplit instance for handling file loading and chunking\n",
    "loader_splitter = ClusteredSplit(file_path=file_path, embeddings=embed_openai_indox, summary_model=openai_qa_indox)\n",
    "\n",
    "# Load and split the document into chunks using ClusteredSplit\n",
    "docs = loader_splitter.load_and_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "XVXR7NPhetnb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:33:04.387804Z",
     "start_time": "2024-07-24T05:33:04.383939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "XVXR7NPhetnb",
    "outputId": "9c64ff3a-c9cd-4dc7-c48e-c233fe5b711d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  They took her pretty clothes away from her, put an old grey bedgown on her, and gave her wooden shoes   Just look at the proud princess, how decked out she is, they cried, and laughed, and led her into the kitchen There she had to do hard work from morning till night, get up before daybreak, carry water, light fires, cook and wash   Besides this, the sisters did her every imaginable injury - they mocked her'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8ffb82df90153",
   "metadata": {
    "id": "8ad8ffb82df90153"
   },
   "source": [
    " Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d8e01f62f1f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:33:14.527207Z",
     "start_time": "2024-07-24T05:33:14.371330Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72d8e01f62f1f4d",
    "outputId": "422e7f26-4a2f-40dd-9d88-cb1e356b3477"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:51:32,661 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.vector_stores import Chroma\n",
    "\n",
    "# Define the collection name within the vector store\n",
    "collection_name = \"sample\"\n",
    "\n",
    "# Create a ChromaVectorStore instance\n",
    "db = Chroma(collection_name=collection_name, embedding_function=embed_openai_indox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c43974ab6c990",
   "metadata": {
    "id": "e84c43974ab6c990"
   },
   "source": [
    "### load and preprocess data\n",
    "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a775a8daa69372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:23.429924Z",
     "start_time": "2024-07-24T05:33:16.398907Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78a775a8daa69372",
    "outputId": "9b927bf5-d3c4-4ad8-a1c0-b3711e67775e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mStoring documents in the vector store\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mDocument added successfully to the vector store.\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mDocuments stored successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db.add(docs=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ddb297b70e98d",
   "metadata": {
    "id": "3c7ddb297b70e98d"
   },
   "source": [
    "### Retrieve relevant information and generate an answer\n",
    "The main purpose of these lines is to perform a query on the vector store to retrieve the most relevant information (top_k=5) and generate an answer using the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eeddd295be41564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:26.416103Z",
     "start_time": "2024-07-24T05:34:26.412646Z"
    },
    "id": "5eeddd295be41564"
   },
   "outputs": [],
   "source": [
    "query = \"How cinderella reach her happy ending?\"\n",
    "from indoxArcg.pipelines.rag import RAG\n",
    "retriever = RAG(llm=openai_qa_indox,vector_store=db,top_k= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a0067afd5532e",
   "metadata": {
    "id": "197a0067afd5532e"
   },
   "source": [
    "infer(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
    "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb95a1c3fcdba812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:34.805479Z",
     "start_time": "2024-07-24T05:34:29.715543Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "eb95a1c3fcdba812",
    "outputId": "028463e5-4552-484b-9337-0d7ecb9d924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving context and scores from the vector database\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating answer without document relevancy filter\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mQuery answered successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Cinderella reaches her happy ending through a series of transformative events facilitated by her inherent goodness, magical assistance, and the eventual recognition of her true worth. Here’s a summary of the key steps leading to her happy ending:\\n\\n1. **Magical Assistance**: After enduring mistreatment from her stepmother and stepsisters, Cinderella seeks solace at her mother’s grave, where she prays to a hazel tree. A little bird appears to grant her wishes, providing her with beautiful dresses and shoes that allow her to attend the royal festival.\\n\\n2. **The Royal Festival**: Cinderella attends the king's festival, where she captivates the prince with her beauty and grace. Each night, she must leave before he discovers her true identity, but she leaves behind a slipper, which becomes a crucial symbol of her identity.\\n\\n3. **The Prince's Search**: After the festival, the prince searches for the owner of the golden slipper. Cinderella’s stepsisters attempt to fit into the slipper, but their deceitful actions reveal their unworthiness. The prince discovers the blood from their attempts, confirming that they are not the true bride.\\n\\n4. **Recognition**: Ultimately, Cinderella is revealed as the rightful owner of the slipper. The prince recognizes her as the beautiful maiden he danced with at the festival.\\n\\n5. **Marriage and Justice**: Cinderella and the prince marry, fulfilling her dreams of love and happiness. Meanwhile, her stepsisters face punishment for their cruelty, symbolizing the triumph of virtue over wickedness.\\n\\nThrough these events, Cinderella transforms from a mistreated girl into a beloved princess, illustrating themes of kindness, resilience, and the eventual reward for goodness.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.infer(query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
