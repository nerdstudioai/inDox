{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fd36cb644c686c",
   "metadata": {},
   "source": [
    "## Deeplake Vector Store\n",
    "Here, we will explore how to work with Deeplake. We are using OpenAI from Indox Api, we should set our INDOX_OPENAI_API_KEY as an environment variable.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/cookbook/indoxArcg/Deeplake_VectorStore.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052f757a9627eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:22.422539Z",
     "start_time": "2024-09-02T03:03:22.368541Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install indoxArcg openai deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1919b4993c54b2",
   "metadata": {},
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxArcg`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indoxArcg\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indoxArcg\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indoxArcg\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indoxArcg/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:22.506606Z",
     "start_time": "2024-09-02T03:03:22.439003Z"
    },
    "collapsed": true,
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "NERD_TOKEN_API= os.getenv(\"NERD_TOKEN_API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215511a752e8ed9b",
   "metadata": {},
   "source": [
    "### Creating an instance of IndoxTetrivalAugmentation\n",
    "\n",
    "To effectively utilize the Indox Retrieval Augmentation capabilities, you must first create an instance of the IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925448e261063192",
   "metadata": {},
   "source": [
    "### Generating response using Indox\n",
    "IndoxApi class is used to handle question-answering task using Indox model. This instance creates IndoxOpenAIEmbedding class to specifying embedding model.By using ClusteredSplit function we can import pdf and text file and split them into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840d601bf111608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:48.306156Z",
     "start_time": "2024-09-02T03:03:23.475621Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5840d601bf111608",
    "outputId": "34a39efd-1e37-478a-83c7-a7c1b255805b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized IndoxOpenAIEmbedding with model: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mClusteredSplit initialized successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting processing for documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1m--Generated 1 clusters--\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mCompleted chunking & clustering process\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mSuccessfully obtained all documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary classes from Indox library\n",
    "from indoxArcg.llms import IndoxApi\n",
    "from indoxArcg.embeddings import IndoxApiEmbedding\n",
    "from indoxArcg.data_loader_splitter import ClusteredSplit\n",
    "\n",
    "# Create instances for API access and text embedding\n",
    "openai_qa_indox = IndoxApi(api_key=INDOX_API_KEY)\n",
    "embed_openai_indox = IndoxApiEmbedding(api_key=INDOX_API_KEY, model=\"text-embedding-3-small\")\n",
    "\n",
    "# Specify the path to your text file\n",
    "file_path = \"sample.txt\"\n",
    "\n",
    "# Create a ClusteredSplit instance for handling file loading and chunking\n",
    "loader_splitter = ClusteredSplit(file_path=file_path, embeddings=embed_openai_indox, summary_model=openai_qa_indox)\n",
    "\n",
    "# Load and split the document into chunks using ClusteredSplit\n",
    "docs = loader_splitter.load_and_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4f79c9ab9f622",
   "metadata": {},
   "source": [
    " Here Deeplake VectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8e01f62f1f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:53.908685Z",
     "start_time": "2024-09-02T03:03:48.306156Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72d8e01f62f1f4d",
    "outputId": "422e7f26-4a2f-40dd-9d88-cb1e356b3477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in /content/vector_store/sample already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.vector_stores import Deeplake\n",
    "collection_name = \"sample\"\n",
    "\n",
    "db = Deeplake(collection_name=collection_name, embedding_function=embed_openai_indox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558c3c6c9708704",
   "metadata": {},
   "source": [
    "### load and preprocess data\n",
    "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6706e55517d7ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:56.554907Z",
     "start_time": "2024-09-02T03:03:53.908685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2::   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='/content/vector_store/sample', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (48, 1536)  float32   None   \n",
      "    id        text      (48, 1)      str     None   \n",
      " metadata     json      (48, 1)      str     None   \n",
      "   text       text      (48, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db.add(docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25eee706fb500090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:56.581676Z",
     "start_time": "2024-09-02T03:03:56.554907Z"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg.pipelines.rag import RAG\n",
    "retriever = RAG(llm=openai_qa_indox,vector_store=db,enable_web_fallback=False,top_k= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6dd7ef78f5665",
   "metadata": {},
   "source": [
    "invoke(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
    "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48544e1ff1cf2e07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:59.848514Z",
     "start_time": "2024-09-02T03:03:56.581676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving context and scores from the vector database\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating answer without document relevancy filter\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mQuery answered successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cinderella reaches her happy ending through a series of transformative events that lead to her escape from a life of hardship and her eventual union with the prince. Here’s a summary of the key steps in her journey:\\n\\n1. **Kindness and Resilience**: Despite being mistreated by her stepmother and stepsisters, Cinderella remains kind and hopeful. Her resilience in the face of adversity sets the foundation for her eventual happiness.\\n\\n2. **The Invitation to the Ball**: When the royal family announces a ball to which all young women are invited, Cinderella dreams of attending. Although her stepfamily forbids her from going, her desire to participate in the event highlights her longing for a better life.\\n\\n3. **The Fairy Godmother**: In'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How cinderella reach her happy ending?\"\n",
    "\n",
    "retriever.infer(query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
