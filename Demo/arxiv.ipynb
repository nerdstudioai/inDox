{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:53:39.123491Z",
     "start_time": "2024-08-21T07:53:39.113484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('api.env')\n",
    "\n",
    "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']"
   ],
   "id": "dfc9daa14417b6e9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-21T07:53:41.462970Z",
     "start_time": "2024-08-21T07:53:41.304064Z"
    }
   },
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mIndoxRetrievalAugmentation initialized\u001B[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:53:55.314723Z",
     "start_time": "2024-08-21T07:53:44.809668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.llms import HuggingFaceModel\n",
    "from indox.embeddings import HuggingFaceEmbedding\n",
    "mistral_qa = HuggingFaceModel(api_key=HUGGINGFACE_API_KEY,model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "embed = HuggingFaceEmbedding(api_key=HUGGINGFACE_API_KEY,model=\"multi-qa-mpnet-base-cos-v1\")"
   ],
   "id": "aad9a7a29fc81465",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitializing HuggingFaceModel with model: mistralai/Mistral-7B-Instruct-v0.2\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mHuggingFaceModel initialized successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitialized HuggingFaceEmbedding with model: multi-qa-mpnet-base-cos-v1\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:53:59.554447Z",
     "start_time": "2024-08-21T07:53:57.893329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.data_connector import ArxivReader\n",
    "\n",
    "reader = ArxivReader()\n",
    "\n",
    "paper_ids = [\"2201.08239\"]\n",
    "documents = reader.load_content(paper_ids)"
   ],
   "id": "ff2ba25cec5cb1a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:54:11.419911Z",
     "start_time": "2024-08-21T07:54:11.410895Z"
    }
   },
   "cell_type": "code",
   "source": "content = documents",
   "id": "2d3e6113f3f5e1ca",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:54:14.564462Z",
     "start_time": "2024-08-21T07:54:13.784629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.splitter import semantic_text_splitter\n",
    "content_chunks = semantic_text_splitter(content,500)"
   ],
   "id": "835fe1c42c4e31df",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:54:47.119492Z",
     "start_time": "2024-08-21T07:54:46.954286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import Chroma\n",
    "db = Chroma(collection_name=\"sample\",embedding_function=embed)\n",
    "indox.connect_to_vectorstore(vectorstore_database=db)"
   ],
   "id": "4636c3ad55b48d94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mConnection to the vector store database established successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.chroma.Chroma at 0x1a842378160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:54:50.752201Z",
     "start_time": "2024-08-21T07:54:49.692474Z"
    }
   },
   "cell_type": "code",
   "source": "indox.store_in_vectorstore(docs= content_chunks)",
   "id": "116efaf8e453f0f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mStoring documents in the vector store\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocument added successfully to the vector store.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocuments stored successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.chroma.Chroma at 0x1a842378160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:55:04.140787Z",
     "start_time": "2024-08-21T07:55:04.125882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what are challenges?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db, llm=mistral_qa, top_k=2)"
   ],
   "id": "a9e7053437d60ca",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:55:06.750513Z",
     "start_time": "2024-08-21T07:55:05.940473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer = retriever.invoke(query)\n",
    "context = retriever.context"
   ],
   "id": "cad8c3510343e8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mRetrieving context and scores from the vector database\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating answer without document relevancy filter\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mAnswering question\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mSending request to Hugging Face API\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mReceived successful response from Hugging Face API\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mQuery answered successfully\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:55:08.652229Z",
     "start_time": "2024-08-21T07:55:08.645210Z"
    }
   },
   "cell_type": "code",
   "source": "answer",
   "id": "a1edb80591b75581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The challenges discussed in the paper are safety and factual grounding for LaMDA (Language Models for Dialog Applications). Safety refers to ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. Factual grounding involves enabling the model to consult external knowledge sources to generate responses grounded in known sources, rather than responses that merely sound plausible.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
