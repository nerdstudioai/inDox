{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quick Start",
   "id": "7e95779738aca6f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/quick_start.ipynb)",
   "id": "f24e01441be4b95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install indox\n",
    "!pip install openai\n",
    "!pip install chromadb"
   ],
   "id": "2e19065cca32a590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:32:40.749405Z",
     "start_time": "2024-07-02T06:32:40.737302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ],
   "id": "88e8c38ba3b8886d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initial Setup\n",
    "\n",
    "The following imports are essential for setting up the Indox application. These imports include the main Indox retrieval augmentation module, question-answering models, embeddings, and data loader splitter."
   ],
   "id": "ac995737f9b2fe6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:32:41.627749Z",
     "start_time": "2024-07-02T06:32:41.623131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "id": "131692307c9154db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:02:41,625 INFO:IndoxRetrievalAugmentation initialized\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating response using OpenAI's language models \n",
    "OpenAIQA class is used to handle question-answering task using OpenAI's language models. This instance creates OpenAiEmbedding class to specifying embedding model. Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ],
   "id": "759db8f502cbd91f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:32:46.132052Z",
     "start_time": "2024-07-02T06:32:42.555134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.llms import OpenAi\n",
    "from indox.embeddings import OpenAiEmbedding\n",
    "openai_qa = OpenAi(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")\n",
    "embed_openai = OpenAiEmbedding(api_key=OPENAI_API_KEY,model=\"text-embedding-3-small\")\n",
    "\n",
    "from indox.vector_stores import ChromaVectorStore\n",
    "db = ChromaVectorStore(collection_name=\"sample\",embedding=embed_openai)\n",
    "indox.connect_to_vectorstore(vectorstore_database=db)"
   ],
   "id": "f32d98545c6d3c3c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:02:43,114 INFO:Initializing OpenAi with model: gpt-3.5-turbo-0125\n",
      "2024-07-02 10:02:43,711 INFO:OpenAi initialized successfully\n",
      "2024-07-02 10:02:45,567 INFO:Initialized OpenAI embeddings with model: text-embedding-3-small\n",
      "2024-07-02 10:02:45,990 INFO:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2024-07-02 10:02:46,126 INFO:Attempting to connect to the vector store database\n",
      "2024-07-02 10:02:46,128 INFO:Connection to the vector store database established successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.Chroma.ChromaVectorStore at 0x2b3487cee40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### load and preprocess data\n",
    "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
   ],
   "id": "1e3408e8f8a8ad17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt",
   "id": "e765b79a32060e9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:32:46.135807Z",
     "start_time": "2024-07-02T06:32:46.133060Z"
    }
   },
   "cell_type": "code",
   "source": "file_path = \"sample.txt\"",
   "id": "1d8e56a9f88e03cf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:32:58.562352Z",
     "start_time": "2024-07-02T06:32:46.136815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.data_loader_splitter import UnstructuredLoadAndSplit\n",
    "loader_splitter = UnstructuredLoadAndSplit(file_path=file_path,max_chunk_size=400)\n",
    "docs = loader_splitter.load_and_chunk()"
   ],
   "id": "827c44ce67f972c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:02:47,993 INFO:Backing off send_request(...) for 0.5s (requests.exceptions.SSLError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1000)'))))\n",
      "2024-07-02 10:02:49,836 INFO:Backing off send_request(...) for 0.2s (requests.exceptions.SSLError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1000)'))))\n",
      "2024-07-02 10:02:50,790 INFO:Backing off send_request(...) for 2.8s (requests.exceptions.SSLError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1000)'))))\n",
      "2024-07-02 10:02:54,022 INFO:Initializing UnstructuredLoadAndSplit\n",
      "2024-07-02 10:02:54,022 INFO:UnstructuredLoadAndSplit initialized successfully\n",
      "2024-07-02 10:02:54,023 INFO:Getting all documents\n",
      "2024-07-02 10:02:54,023 INFO:Starting processing\n",
      "2024-07-02 10:02:54,889 ERROR:Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1000)'))))\n",
      "2024-07-02 10:02:58,554 INFO:Created initial document elements\n",
      "2024-07-02 10:02:58,555 INFO:Using title-based chunking\n",
      "2024-07-02 10:02:58,559 INFO:Completed chunking process\n",
      "2024-07-02 10:02:58,560 INFO:Successfully obtained all documents\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:33:04.144301Z",
     "start_time": "2024-07-02T06:32:58.563358Z"
    }
   },
   "cell_type": "code",
   "source": "indox.store_in_vectorstore(docs=docs)",
   "id": "4557891dec337e31",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:02:58,565 INFO:Storing documents in the vector store\n",
      "2024-07-02 10:03:01,823 INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-02 10:03:04,140 INFO:Document added successfully to the vector store.\n",
      "2024-07-02 10:03:04,141 INFO:Documents stored successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.Chroma.ChromaVectorStore at 0x2b3487cee40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retrieve relevant information and generate an answer\n",
    "The main purpose of these lines is to perform a query on the vector store to retrieve the most relevant information (top_k=5) and generate an answer using the language model."
   ],
   "id": "cd6bd4924ad116fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:33:04.148254Z",
     "start_time": "2024-07-02T06:33:04.145309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"How Cinderella reach her happy ending?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db, llm=openai_qa, top_k=5)"
   ],
   "id": "593ec3a85c796115",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "invoke(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
    "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
   ],
   "id": "9e778403c8d864c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:37:40.974481Z",
     "start_time": "2024-07-02T06:37:35.766347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer = retriever.invoke(query)\n",
    "context = retriever.context"
   ],
   "id": "58d79450c0807286",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:07:35,768 INFO:Retrieving context and scores from the vector database\n",
      "2024-07-02 10:07:37,064 INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-02 10:07:37,069 INFO:Generating answer without document relevancy filter\n",
      "2024-07-02 10:07:37,070 INFO:Answering question\n",
      "2024-07-02 10:07:37,071 INFO:Generating response\n",
      "2024-07-02 10:07:40,970 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-02 10:07:40,972 INFO:Response generated successfully\n",
      "2024-07-02 10:07:40,972 INFO:Query answered successfully\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### With AgenticRag\n",
    "\n",
    "AgenticRag stands for Agentic Retrieval-Augmented Generation. This concept combines retrieval-based methods and generation-based methods in natural language processing (NLP). The key idea is to enhance the generative capabilities of a language model by incorporating relevant information retrieved from a database or a vector store. \n",
    " AgenticRag is designed to provide more contextually rich and accurate responses by utilizing external knowledge sources. It retrieves relevant pieces of information (chunks) from a vector store based on a query and then uses a language model to generate a comprehensive response that incorporates this retrieved information."
   ],
   "id": "486878b3d49c9871"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:05:55.712801Z",
     "start_time": "2024-06-09T05:05:48.941354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = indox.AgenticRag(llm=openai_qa,vector_database=db,top_k=5)\n",
    "agent.run(query)"
   ],
   "id": "394533a0e6ab8228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Relevant doc\n",
      "Relevant doc\n",
      "Not Relevant doc\n",
      "Not Relevant doc\n",
      "Not Relevant doc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Cinderella reached her happy ending by receiving a branch from the hazel-bush from the prince, planting it on her mother's grave, and weeping and praying beneath it. The branch grew into a handsome tree, and a little white bird always came to the tree, bringing her comfort and assistance.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "6ef035b53ef74d65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:57:27.131723Z",
     "start_time": "2024-07-02T06:57:15.072106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.evaluation import Evaluation\n",
    "evaluator = Evaluation([\"BertScore\", \"Toxicity\",  \"Reliability\", \"Fairness\" , \"Readibility\"])"
   ],
   "id": "750a052ed290bdf9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:27:22,324 INFO:Use pytorch device: cpu\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:57:32.071506Z",
     "start_time": "2024-07-02T06:57:29.153596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = {\n",
    "    \"question\" : query,\n",
    "    \"answer\" : answer,\n",
    "    \"context\" : context\n",
    "}\n",
    "result = evaluator(inputs)"
   ],
   "id": "caeb4a7cb21df923",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9eb4a59dbd7c439b8b514decbe503037"
      },
      "application/json": {
       "n": 0,
       "total": 1,
       "elapsed": 0.010510921478271484,
       "ncols": null,
       "nrows": null,
       "prefix": "Batches",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f5252e1e84f4ad7a84fa2a8fda2ca64"
      },
      "application/json": {
       "n": 0,
       "total": 1,
       "elapsed": 0.004000425338745117,
       "ncols": null,
       "nrows": null,
       "prefix": "Batches",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76d383160a4a44e1bbcdf383b8238fc1"
      },
      "application/json": {
       "n": 0,
       "total": 1,
       "elapsed": 0.005513668060302734,
       "ncols": null,
       "nrows": null,
       "prefix": "Batches",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a76ad5c6d4674b23b801b62c6873d7ed"
      },
      "application/json": {
       "n": 0,
       "total": 1,
       "elapsed": 0.004008054733276367,
       "ncols": null,
       "nrows": null,
       "prefix": "Batches",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5843a130485d4ff98c7fa65ce8cf19e1"
      },
      "application/json": {
       "n": 0,
       "total": 1,
       "elapsed": 0.004518032073974609,
       "ncols": null,
       "nrows": null,
       "prefix": "Batches",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T06:57:33.713540Z",
     "start_time": "2024-07-02T06:57:33.707971Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "8af894ed689460b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    0\n",
       "Precision                    0.493488\n",
       "Recall                       0.517235\n",
       "F1-score                     0.505083\n",
       "Toxicity                     0.081307\n",
       "hallucination_score          0.620000\n",
       "Fairness                     0.496180\n",
       "Perplexity                  38.828209\n",
       "ARI                         12.800000\n",
       "Flesch-Kincaid Grade Level  10.100000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.493488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.517235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.505083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toxicity</th>\n",
       "      <td>0.081307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucination_score</th>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairness</th>\n",
       "      <td>0.496180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perplexity</th>\n",
       "      <td>38.828209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARI</th>\n",
       "      <td>12.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flesch-Kincaid Grade Level</th>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34dd57882af42333"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
