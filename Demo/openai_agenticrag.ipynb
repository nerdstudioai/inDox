{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/openai_agenticrag.ipynb)",
   "id": "cd1e2aa3a497e7b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install indox\n",
    "!pip install openai\n",
    "!pip install chromadb\n",
    "!pip install duckduckgo-search"
   ],
   "id": "c2ab8144e1eb7773"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Agentic RAG\n",
    "Here, we will explore how to work with Agentic RAG. We are using OpenAI and we should set our OPENAI_API_KEY as an environment variable."
   ],
   "id": "e17682c35969a25"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-07T08:35:39.812104Z",
     "start_time": "2024-07-07T08:35:39.757293Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating an instance of IndoxRetrievalAugmentation\n",
    "You must first create an instance of IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ],
   "id": "cc1864f1b50f95c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:35:55.019731Z",
     "start_time": "2024-07-07T08:35:39.813109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "from indox.llms import OpenAi\n",
    "from indox.embeddings import OpenAiEmbedding\n",
    "from indox.data_loader_splitter import SimpleLoadAndSplit"
   ],
   "id": "f86ed3314b0d078",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create OpenAi model as LLM_model and OpenAiEmbedding as Embedding model and using them to generate response.",
   "id": "a81302a67ec0d5a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:35:57.024560Z",
     "start_time": "2024-07-07T08:35:55.020018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indox = IndoxRetrievalAugmentation()\n",
    "llm_model = OpenAi(api_key=OPENAI_API_KEY,model=\"gpt-3.5-turbo-0125\")\n",
    "embed = OpenAiEmbedding(api_key=OPENAI_API_KEY,model=\"text-embedding-3-small\")"
   ],
   "id": "7b93033e005b8049",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:05:55,022 INFO:IndoxRetrievalAugmentation initialized\n",
      "2024-07-07 12:05:55,025 INFO:Initializing OpenAi with model: gpt-3.5-turbo-0125\n",
      "2024-07-07 12:05:55,647 INFO:OpenAi initialized successfully\n",
      "2024-07-07 12:05:57,022 INFO:Initialized OpenAI embeddings with model: text-embedding-3-small\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:35:57.032105Z",
     "start_time": "2024-07-07T08:35:57.026083Z"
    }
   },
   "cell_type": "code",
   "source": "indox.__version__",
   "id": "62398709ecd1bae2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.13'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### You can download the file from the below address ",
   "id": "2a0fb03eccb8cf95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt",
   "id": "7174373485eda383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess Data\n",
    "using SimpleLoadAndSplit class to preprocess text data from a file, split text into chunks"
   ],
   "id": "f9e40fa02a3110d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:35:57.833513Z",
     "start_time": "2024-07-07T08:35:57.828022Z"
    }
   },
   "cell_type": "code",
   "source": "loader_splitter = SimpleLoadAndSplit(file_path=\"sample.txt\",remove_sword=False)",
   "id": "3aaeda535bc2c497",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:05:57,830 INFO:Initializing UnstructuredLoadAndSplit\n",
      "2024-07-07 12:05:57,831 INFO:UnstructuredLoadAndSplit initialized successfully\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:36:02.460365Z",
     "start_time": "2024-07-07T08:35:58.849287Z"
    }
   },
   "cell_type": "code",
   "source": "docs = loader_splitter.load_and_chunk()",
   "id": "e173124b75795645",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:05:58,850 INFO:Getting all documents\n",
      "2024-07-07 12:05:58,851 INFO:Starting processing\n",
      "2024-07-07 12:05:58,886 INFO:Created initial document elements\n",
      "2024-07-07 12:06:02,457 INFO:Completed chunking process\n",
      "2024-07-07 12:06:02,458 INFO:Successfully obtained all documents\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create ChromaVectoreStore instance\n",
    "Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ],
   "id": "8f82e6f2cb8dc57f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:36:04.766362Z",
     "start_time": "2024-07-07T08:36:03.643065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import ChromaVectorStore\n",
    "\n",
    "# Define the collection name within the vector store\n",
    "collection_name = \"sample\"\n",
    "\n",
    "# Create a ChromaVectorStore instance\n",
    "db = ChromaVectorStore(collection_name=collection_name, embedding=embed)\n",
    "\n",
    "# Connect to the vector store using the provided database instance\n",
    "indox.connect_to_vectorstore(vectorstore_database=db)"
   ],
   "id": "f8a8b4ca4328777e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:06:04,504 INFO:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2024-07-07 12:06:04,762 INFO:Attempting to connect to the vector store database\n",
      "2024-07-07 12:06:04,763 INFO:Connection to the vector store database established successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.Chroma.ChromaVectorStore at 0x195f52efb30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "store the chunks in the vector store that was set up previously.",
   "id": "9535306c09023386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:36:28.592532Z",
     "start_time": "2024-07-07T08:36:26.393062Z"
    }
   },
   "cell_type": "code",
   "source": "indox.store_in_vectorstore(docs=docs)",
   "id": "20b205c7b5cb3521",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:06:26,394 INFO:Storing documents in the vector store\n",
      "2024-07-07 12:06:28,051 INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:06:28,589 INFO:Document added successfully to the vector store.\n",
      "2024-07-07 12:06:28,589 INFO:Documents stored successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.Chroma.ChromaVectorStore at 0x195f52efb30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Retrieve relevant information by question-answering model\n",
    "At this step we are using QuestionAnswer model and try to retrieve the answer just by our file and without any agent"
   ],
   "id": "f18cb82b795d12eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:40:04.712616Z",
     "start_time": "2024-07-07T08:40:04.708863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Where does messi plays right now?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db,llm=llm_model,top_k=3)"
   ],
   "id": "71e64d760fa319f0",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:40:09.572410Z",
     "start_time": "2024-07-07T08:40:05.388985Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.invoke(query)",
   "id": "2d3ed87a223398fb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:10:05,391 INFO:Retrieving context and scores from the vector database\n",
      "2024-07-07 12:10:07,036 INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:07,179 INFO:Generating answer without document relevancy filter\n",
      "2024-07-07 12:10:07,179 INFO:Answering question\n",
      "2024-07-07 12:10:07,180 INFO:Generating response\n",
      "2024-07-07 12:10:09,567 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:09,569 INFO:Response generated successfully\n",
      "2024-07-07 12:10:09,569 INFO:Query answered successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the given context does not contain any information about where Lionel Messi currently plays.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Retrieve information by using Agnet\n",
    "Here we are using Agent to retrieve answer. As you can see, our last try was unsuccessful but now after the agent couldn't find the answer it started to search on the internet.\n",
    "Note: to be more familiar with AgenticRAG pleas read [this page](\"https://docs.osllm.ai/agenticRag.html\")"
   ],
   "id": "b3846ee63c84dd1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T08:40:26.184663Z",
     "start_time": "2024-07-07T08:40:15.525911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = indox.AgenticRag(llm=llm_model,vector_database=db,top_k=3)\n",
    "agent.run(query)"
   ],
   "id": "5a145c1a46ced87d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:10:17,315 INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:17,412 INFO:Generating response\n",
      "2024-07-07 12:10:18,649 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:18,739 INFO:Response generated successfully\n",
      "2024-07-07 12:10:18,740 INFO:Not relevant doc\n",
      "2024-07-07 12:10:18,740 INFO:Generating response\n",
      "2024-07-07 12:10:19,505 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:19,507 INFO:Response generated successfully\n",
      "2024-07-07 12:10:19,507 INFO:Not relevant doc\n",
      "2024-07-07 12:10:19,508 INFO:Generating response\n",
      "2024-07-07 12:10:20,220 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:20,222 INFO:Response generated successfully\n",
      "2024-07-07 12:10:20,222 INFO:Not relevant doc\n",
      "2024-07-07 12:10:20,223 INFO:No Relevant document found, Start web search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Relevant Context Found, Start Searching On Web...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:10:23,084 INFO:Answering question\n",
      "2024-07-07 12:10:23,084 INFO:Generating response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Base On Web Search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:10:24,077 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:24,213 INFO:Response generated successfully\n",
      "2024-07-07 12:10:24,214 INFO:Checking hallucination for answer\n",
      "2024-07-07 12:10:24,215 INFO:Generating response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check For Hallucination In Generated Answer Base On Web Search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 12:10:24,884 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:24,884 INFO:Response generated successfully\n",
      "2024-07-07 12:10:24,885 INFO:Hallucination detected, Regenerate the answer...\n",
      "2024-07-07 12:10:24,885 INFO:Answering question\n",
      "2024-07-07 12:10:24,886 INFO:Generating response\n",
      "2024-07-07 12:10:26,180 INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-07 12:10:26,181 INFO:Response generated successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Lionel Messi currently plays for Major League Soccer's Inter Miami CF.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "751c15421f42ebfa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
