{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using Multi-Query Retrieval with GutenbergReader for Accessing Project Gutenberg Books\n",
    "In this notebook, we will demonstrate how to enhance your document retrieval by using Multi-Query Retrieval (MQR) with the `GutenbergReader` class for accessing books from Project Gutenberg. Multi-Query Retrieval helps improve the comprehensiveness of retrieved data by breaking down a single query into multiple sub-queries, each focusing on different aspects of the question. This technique allows for more accurate and diverse retrieval of content, making it particularly useful for research and question-answering systems.\n",
    "\n",
    "To get started, ensure you have your Project Gutenberg book IDs ready for fetching the content. This setup is crucial for accessing and processing book data effectively.\n",
    "\n",
    "To begin, ensure you have set up your environment variables and API keys in Python using the dotenv library. This is crucial for securely managing sensitive information, such as API keys, especially when using services like HuggingFace. Ensure your `HUGGINGFACE_API_KEY` and `INDOX_API_KEY` are defined in the `.env` file to avoid hardcoding sensitive data into your codebase, thus enhancing security and maintainability.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/multiquery_guten_chroma.ipynb)"
   ],
   "id": "3b8b50c8955b671b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install indox\n",
    "!pip install chromadb\n",
    "!pip install beautifulsoup4\n",
    "!pip install sentence_transformers\n",
    "!pip install semantic_text_splitter"
   ],
   "id": "402b1185e6566f03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indox`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indox\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indox_judge\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indox\n",
    "    ```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indox/bin/activate\n",
    "    ```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ],
   "id": "34666a88534518cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import Essential Libraries\n",
    "\n",
    "Next, we import the essential libraries for our Indox question-answering system:\n",
    "\n",
    "- `IndoxRetrievalAugmentation`: Enhances the retrieval process by improving the relevance and quality of the documents retrieved, leading to better QA performance.\n",
    "- `OpenAI Model`: A powerful question-answering model provided by OpenAI. It leverages advanced multi-query retrieval and state-of-the-art language understanding to deliver more comprehensive and precise answers by capturing diverse aspects of the query.\n",
    "- `HuggingFaceEmbedding`: This library uses Hugging Face embeddings to enrich semantic understanding, making it easier to capture the contextual meaning of the text.\n",
    "- `SemanticTextSplitter`: utilizes a Hugging Face tokenizer to intelligently split text into chunks based on a specified maximum number of tokens, ensuring that each chunk maintains semantic coherence."
   ],
   "id": "4961379b71c5d3fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:32:26.657279Z",
     "start_time": "2024-09-05T09:32:26.639717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('api.env')\n",
    "\n",
    "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
    "INDOX_API_KEY = os.environ['INDOX_API_KEY']"
   ],
   "id": "dfc9daa14417b6e9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-05T09:32:29.313986Z",
     "start_time": "2024-09-05T09:32:29.240981Z"
    }
   },
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mIndoxRetrievalAugmentation initialized\u001B[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building the GutenbergReader System and Initializing Models\n",
    "Next, we will build our `GutenbergReader` system and initialize the necessary models for processing content from Project Gutenberg. This setup will enable us to effectively retrieve and handle texts from Gutenberg's collection, leveraging these models to support various research and question-answering tasks."
   ],
   "id": "e631854ff3240f6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:35:00.250582Z",
     "start_time": "2024-09-05T09:34:51.133802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.llms import IndoxApi\n",
    "from indox.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "openai_model = IndoxApi(api_key=INDOX_API_KEY)\n",
    "embed = HuggingFaceEmbedding(api_key=HUGGINGFACE_API_KEY,model=\"multi-qa-mpnet-base-cos-v1\")"
   ],
   "id": "aad9a7a29fc81465",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitialized HuggingFaceEmbedding with model: multi-qa-mpnet-base-cos-v1\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the GutenbergReader for Retrieving Book Content\n",
    "To demonstrate the capabilities of our `GutenbergReader` system and its integration with `Indox`, we will use a sample book from Project Gutenberg. This book will serve as our reference data, which we will use for testing and evaluation of the system."
   ],
   "id": "4c29659851115c85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:35:15.339997Z",
     "start_time": "2024-09-05T09:35:13.331983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.data_connectors import GutenbergReader\n",
    "\n",
    "reader = GutenbergReader()\n",
    "\n",
    "book_id = \"11\"  # Alice's Adventures in Wonderland\n",
    "content = reader.get_content(book_id)"
   ],
   "id": "ff2ba25cec5cb1a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Splitting Content into Manageable Chunks\n",
    "We use the `SemanticTextSplitter` function from the `indox.splitter` module to divide the retrieved content into smaller, meaningful chunks."
   ],
   "id": "bf7b838e3518614d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:35:24.492132Z",
     "start_time": "2024-09-05T09:35:23.229297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.splitter import SemanticTextSplitter\n",
    "splitter = SemanticTextSplitter(400)\n",
    "content_chunks = splitter.split_text(content)"
   ],
   "id": "835fe1c42c4e31df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Storing and Indexing Content with Chroma\n",
    "We use the `Chroma` vector store from the `indox.vector_stores` module to store and index the content chunks. By creating a collection named \"sample\" and applying an embedding function (`embed`), we convert each chunk into a vector for efficient retrieval. The `add` method then adds these vectors to the database, enabling scalable and effective search for question-answering tasks."
   ],
   "id": "41c4ec0584b71cc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:35:47.992138Z",
     "start_time": "2024-09-05T09:35:44.010305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import Chroma\n",
    "db = Chroma(collection_name=\"sample\",embedding_function=embed)\n",
    "db.add(docs=content_chunks)\n"
   ],
   "id": "4636c3ad55b48d94",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 13:05:44,498 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mStoring documents in the vector store\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0909ffa913be4f52acda572c7a2a565e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocument added successfully to the vector store.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocuments stored successfully\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Querying Data with GPT and Indox Multi-Query Retrieval\n",
    "With our multi-query retrieval system using GPT and Indox fully set up, we are ready to test it using a sample query. This test will demonstrate how effectively our system can retrieve and process information from a vector database using the GPT model.\n",
    "\n",
    "We’ll use the following sample query to evaluate our system:\n",
    "\n",
    "- Query: \"Who is the speaker talking to in the text?\"\n",
    "\n",
    "This query will be processed by the multi-query retrieval system, where multiple sub-queries will be generated and run against the vector database to retrieve relevant information and generate an accurate response based on the context."
   ],
   "id": "49a60699b567fcb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:42:40.710765Z",
     "start_time": "2024-09-05T09:42:35.978050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indox.initialize_multi_query_retrieval(llm=openai_model, vector_database=db, top_k=3)\n",
    "\n",
    "query = \"Who is the speaker talking to in the text?\"\n",
    "\n",
    "answer = indox.run_multi_query_retrieval(query)"
   ],
   "id": "e5491a3fc81dcc93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mMulti-query retrieval initialized\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mRunning multi-query retrieval for: Who is the speaker talking to in the text?\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerated queries: ['Here are three different queries you could use to gather information to determine who the speaker is talking to in a given text:', '1. **Contextual Analysis Query**: \"What contextual clues in the text indicate the identity or characteristics of the audience or recipient of the speaker\\'s message?\"', '2. **Dialogue and Interaction Query**: \"Are there any direct references or dialogue exchanges in the text that reveal who the speaker is addressing, such as names, titles, or pronouns?\"', '3. **Tone and Purpose Query**: \"What is the tone and purpose of the speaker\\'s message, and how might these elements suggest the intended audience or recipient in the text?\"']\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c8e92354bd749ac9621da0d52f61eb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90d22f0bd0444a1eb73afbe72d1f62e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a876bf78fb134c0599879d106682747c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa4249d13b9240c389002b6d92f27a5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mRetrieved 12 relevant passages\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerated final response\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:42:44.754613Z",
     "start_time": "2024-09-05T09:42:44.735760Z"
    }
   },
   "cell_type": "code",
   "source": "answer",
   "id": "a1edb80591b75581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speaker, Alice, is talking to the Mouse in the text. She addresses the Mouse directly, asking if it knows the way out of the pool and expressing her tiredness of swimming.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
