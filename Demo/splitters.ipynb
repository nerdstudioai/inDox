{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:38:14.526708Z",
     "start_time": "2024-08-24T16:38:14.082104Z"
    }
   },
   "cell_type": "code",
   "source": "from indox.splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, MarkdownTextSplitter, AI21SemanticTextSplitter",
   "id": "c9fe1fb592605ec1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T08:53:44.408586Z",
     "start_time": "2024-08-24T08:53:44.394454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text = \"\"\"This is a long piece of text that we want to split into smaller chunks.\n",
    "It contains multiple sentences and paragraphs. We'll use this to test our text splitter.\n",
    "\n",
    "This is a new paragraph. It should be split on the paragraph boundary first.\n",
    "Then, if needed, it will be split into smaller chunks.\"\"\"\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 40)\n"
   ],
   "id": "44ca14446cf2e24e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "This is a long piece of text that we want to split into smaller chunks.\n",
      "----------------------------------------\n",
      "Chunk 2:\n",
      "It contains multiple sentences and paragraphs. We'll use this to test our text splitter.\n",
      "----------------------------------------\n",
      "Chunk 3:\n",
      "This is a new paragraph. It should be split on the paragraph boundary first.\n",
      "----------------------------------------\n",
      "Chunk 4:\n",
      "Then, if needed, it will be split into smaller chunks.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T08:54:07.976071Z",
     "start_time": "2024-08-24T08:54:07.966086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text = \"\"\"This is a long piece of text that we want to split into smaller chunks.\n",
    "It contains multiple sentences and paragraphs. We'll use this to test our text splitter.\n",
    "\n",
    "This is a new paragraph. It should be split on the paragraph boundary first.\n",
    "Then, if needed, it will be split into smaller chunks.\"\"\"\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 40)"
   ],
   "id": "7f6324dcfc75feca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "This is a long piece of text that we want to split into smaller chunks.\n",
      "It contains multiple sentences and paragraphs. We'll use this to test our text splitter.\n",
      "----------------------------------------\n",
      "Chunk 2:\n",
      "This is a new paragraph. It should be split on the paragraph boundary first.\n",
      "Then, if needed, it will be split into smaller chunks.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T08:54:46.971302Z",
     "start_time": "2024-08-24T08:54:46.956465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "markdown_text = \"\"\"\n",
    "# Main Title\n",
    "\n",
    "## Section 1\n",
    "\n",
    "This is content for section 1.\n",
    "\n",
    "## Section 2\n",
    "\n",
    "This is content for section 2.\n",
    "\n",
    "### Subsection 2.1\n",
    "\n",
    "More detailed content here.\n",
    "\n",
    "## Section 3\n",
    "\n",
    "Final section content.\n",
    "\"\"\"\n",
    "\n",
    "splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "chunks = splitter.split_text(markdown_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 40)"
   ],
   "id": "11bf145088ff0823",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "# Main Title\n",
      "\n",
      "## \n",
      "## Section 1\n",
      "\n",
      "This is content for section 1.\n",
      "\n",
      "##\n",
      "----------------------------------------\n",
      "Chunk 2:\n",
      "Section 2\n",
      "\n",
      "This is content for section 2.\n",
      "\n",
      "### Subsection 2.1\n",
      "\n",
      "More detailed content here.\n",
      "\n",
      "##\n",
      "----------------------------------------\n",
      "Chunk 3:\n",
      "Section 3\n",
      "\n",
      "Final section content.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:38:20.865223Z",
     "start_time": "2024-08-24T16:38:20.847202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('api.env')\n",
    "AI21_API_KEY = os.getenv('AI21_API_KEY')"
   ],
   "id": "89c5efc7ab02e979",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:38:25.020167Z",
     "start_time": "2024-08-24T16:38:23.065659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TEXT = (\n",
    "    \"We’ve all experienced reading long, tedious, and boring pieces of text - financial reports, \"\n",
    "    \"legal documents, or terms and conditions (though, who actually reads those terms and conditions to be honest?).\\n\"\n",
    "    \"Imagine a company that employs hundreds of thousands of employees. In today's information \"\n",
    "    \"overload age, nearly 30% of the workday is spent dealing with documents. There's no surprise \"\n",
    "    \"here, given that some of these documents are long and convoluted on purpose (did you know that \"\n",
    "    \"reading through all your privacy policies would take almost a quarter of a year?). Aside from \"\n",
    "    \"inefficiency, workers may simply refrain from reading some documents (for example, Only 16% of \"\n",
    "    \"Employees Read Their Employment Contracts Entirely Before Signing!).\\nThis is where AI-driven summarization \"\n",
    "    \"tools can be helpful: instead of reading entire documents, which is tedious and time-consuming, \"\n",
    "    \"users can (ideally) quickly extract relevant information from a text. With large language models, \"\n",
    "    \"the development of those tools is easier than ever, and you can offer your users a summary that is \"\n",
    "    \"specifically tailored to their preferences.\\nLarge language models naturally follow patterns in input \"\n",
    "    \"(prompt), and provide coherent completion that follows the same patterns. For that, we want to feed \"\n",
    "    'them with several examples in the input (\"few-shot prompt\"), so they can follow through. '\n",
    "    \"The process of creating the correct prompt for your problem is called prompt engineering, \"\n",
    "    \"and you can read more about it here.\"\n",
    ")\n",
    "\n",
    "semantic_text_splitter = AI21SemanticTextSplitter()\n",
    "chunks = semantic_text_splitter.split_text(TEXT)\n",
    "\n",
    "print(f\"The text has been split into {len(chunks)} chunks.\")\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "    print(\"====\")"
   ],
   "id": "f9f1743cbbe55ec7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been split into 3 chunks.\n",
      "We’ve all experienced reading long, tedious, and boring pieces of text - financial reports, legal documents, or terms and conditions (though, who actually reads those terms and conditions to be honest?).\n",
      "\n",
      "Imagine a company that employs hundreds of thousands of employees.\n",
      "\n",
      "In today's information overload age, nearly 30% of the workday is spent dealing with documents.\n",
      "\n",
      "There's no surprise here, given that some of these documents are long and convoluted on purpose (did you know that reading through all your privacy policies would take almost a quarter of a year?).\n",
      "\n",
      "Aside from inefficiency, workers may simply refrain from reading some documents (for example, Only 16% of Employees Read Their Employment Contracts Entirely Before Signing!).\n",
      "====\n",
      "This is where AI-driven summarization tools can be helpful: instead of reading entire documents, which is tedious and time-consuming, users can (ideally) quickly extract relevant information from a text.\n",
      "\n",
      "With large language models, the development of those tools is easier than ever, and you can offer your users a summary that is specifically tailored to their preferences.\n",
      "====\n",
      "Large language models naturally follow patterns in input (prompt), and provide coherent completion that follows the same patterns.\n",
      "\n",
      "For that, we want to feed them with several examples in the input (\"few-shot prompt\"), so they can follow through.\n",
      "\n",
      "The process of creating the correct prompt for your problem is called prompt engineering, and you can read more about it here.\n",
      "====\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
